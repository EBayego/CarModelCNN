{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e60631de-5200-42db-8048-e18cde1bf7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e247cc1-c33a-48d5-a717-1ee240444855",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor(),\n",
    "])\n",
    "train_data = ImageFolder(root=\"./CarsDataset/train\", transform=transform)\n",
    "test_data = ImageFolder(root=\"./CarsDataset/test\", transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "444ef8ca-99ca-4e8f-a735-0ce9a1659a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes, seed = 155):\n",
    "        super(CNN, self).__init__()\n",
    "        self.seed = torch.manual_seed(seed)\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=8, stride=4)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=4, stride=2)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, stride=1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.conv4 = nn.Conv2d(64, 128, kernel_size=3, stride=1)\n",
    "        self.bn4 = nn.BatchNorm2d(128)\n",
    "    \n",
    "        self.fc1 = nn.Linear(10*10*128, 512) \n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x): #el input de cada uno es el input de la conv, por el tamaño de la imagen, y el output lo mismo. El tamaño de la imagen se reduce en kernel-stride\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "    \n",
    "        x = x.view(x.size(0), -1)\n",
    "    \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "    def predict_image(self, image_path):\n",
    "        image = transform(Image.open(image_path)).unsqueeze(0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = self(image)\n",
    "\n",
    "        probabilities = torch.softmax(output, dim=1)[0]\n",
    "        predicted_label = torch.argmax(probabilities).item()\n",
    "\n",
    "        class_names = train_data.classes\n",
    "        predicted_class = class_names[predicted_label]\n",
    "\n",
    "        print(f'Predicted Class for {image_path}: {predicted_class}')\n",
    "        for i, prob in enumerate(probabilities):\n",
    "            print(f'{class_names[i]}: {prob:.4f}')\n",
    "\n",
    "model = CNN(num_classes=len(train_data.classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e21da92f-18a9-4310-b7da-c701ca62d299",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001 #tested with many, but this one seems the best\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b18aff50-6563-4736-889b-5ead759f9535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training Loss: 1.746369955653236\n",
      "Epoch 2, Training Loss: 1.4759357724870954\n",
      "Epoch 3, Training Loss: 1.2855018950643993\n",
      "Epoch 4, Training Loss: 1.0965463093348913\n",
      "Epoch 5, Training Loss: 0.9010610202948253\n",
      "Epoch 6, Training Loss: 0.7187214011237735\n",
      "Epoch 7, Training Loss: 0.571584529536111\n",
      "Epoch 8, Training Loss: 0.4017501447172392\n",
      "Epoch 9, Training Loss: 0.30280913951851074\n",
      "Epoch 10, Training Loss: 0.2125521719455719\n",
      "Epoch 11, Training Loss: 0.17461413180544264\n",
      "Epoch 12, Training Loss: 0.15315540741596903\n",
      "Epoch 13, Training Loss: 0.12239125074730033\n",
      "Epoch 14, Training Loss: 0.09930742314706247\n",
      "Epoch 15, Training Loss: 0.07264547791065915\n",
      "Epoch 16, Training Loss: 0.07247684808403608\n",
      "Epoch 17, Training Loss: 0.051697693379329786\n",
      "Epoch 18, Training Loss: 0.058978976542130114\n",
      "Epoch 19, Training Loss: 0.07629377153879476\n",
      "Epoch 20, Training Loss: 0.07411120342245946\n",
      "Epoch 21, Training Loss: 0.06025229925954981\n",
      "Epoch 22, Training Loss: 0.03810229376291058\n",
      "Epoch 23, Training Loss: 0.03948655612378692\n",
      "Epoch 24, Training Loss: 0.01502105127271664\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "epochs = 24\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}, Training Loss: {running_loss/len(train_loader)}\")\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c9041cb-b2c8-4d1f-a0d5-11fdbeb0c450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 67.65067650676507%\n"
     ]
    }
   ],
   "source": [
    "# Evaluation of the model\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print(f\"Accuracy on test set: {100 * correct / total}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "096c1dfb-c034-40ba-a801-d145f770cc14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class for ./CarsDataset/extra\\Audi.jpg: Audi\n",
      "Audi: 1.0000\n",
      "Hyundai Creta: 0.0000\n",
      "Mahindra Scorpio: 0.0000\n",
      "Rolls Royce: 0.0000\n",
      "Swift: 0.0000\n",
      "Tata Safari: 0.0000\n",
      "Toyota Innova: 0.0000\n",
      "Predicted Class for ./CarsDataset/extra\\PruebaMahindraScorpio.jpg: Toyota Innova\n",
      "Audi: 0.0000\n",
      "Hyundai Creta: 0.0005\n",
      "Mahindra Scorpio: 0.0000\n",
      "Rolls Royce: 0.0000\n",
      "Swift: 0.0001\n",
      "Tata Safari: 0.0000\n",
      "Toyota Innova: 0.9995\n",
      "Predicted Class for ./CarsDataset/extra\\PruebaMahindraScorpio2.png: Audi\n",
      "Audi: 0.6270\n",
      "Hyundai Creta: 0.0045\n",
      "Mahindra Scorpio: 0.0000\n",
      "Rolls Royce: 0.0000\n",
      "Swift: 0.0000\n",
      "Tata Safari: 0.0000\n",
      "Toyota Innova: 0.3684\n",
      "Predicted Class for ./CarsDataset/extra\\PruebaRollsRoyce.jpg: Rolls Royce\n",
      "Audi: 0.0000\n",
      "Hyundai Creta: 0.0000\n",
      "Mahindra Scorpio: 0.0000\n",
      "Rolls Royce: 1.0000\n",
      "Swift: 0.0000\n",
      "Tata Safari: 0.0000\n",
      "Toyota Innova: 0.0000\n"
     ]
    }
   ],
   "source": [
    "image_folder = \"./CarsDataset/extra\"\n",
    "image_paths = [os.path.join(image_folder, filename) for filename in os.listdir(image_folder) if filename.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "\n",
    "for image_path in image_paths:\n",
    "    model.predict_image(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae9952f-eec2-4b77-b7de-340789542399",
   "metadata": {},
   "source": [
    "___\n",
    "SAVE AND LOAD FUNCTIONS\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "668b9257-4943-4a2c-9571-1aed5cdf7feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "torch.save({\n",
    "    'epoch': epochs,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'loss': running_loss/len(train_loader)\n",
    "}, 'trained_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af09bd4e-ce6f-4ea8-b3d6-ac4db68b7d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "model = CNN(num_classes=len(train_data.classes))\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "checkpoint = torch.load('trained_model.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f83de7-bbb3-4176-9bf4-77304c1f34c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
